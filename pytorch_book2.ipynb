{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_book2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15q-XyA9qGoDIi_0RT2fYLpWD0S26jnB8",
      "authorship_tag": "ABX9TyN2yeH9CLtsY5Azkt93eJZs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/pytorch_book')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G2ppHEZD-j6D",
        "outputId": "7f0e6304-5b1c-4ce1-dc31-8d997b03da67"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/pytorch_book'"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojYuG6K33NMw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 20)"
      ],
      "metadata": {
        "id": "6kLQXtKl3wmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom block\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)\n",
        "        self.out = nn.Linear(256, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.out(F.relu(self.hidden(x)))"
      ],
      "metadata": {
        "id": "2jQ1ECVe3SAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MLP()\n",
        "net(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkomBT423rNK",
        "outputId": "ad9b5bd2-a15d-442d-80e7-cb10dea40029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2075, -0.1071, -0.0172, -0.1940, -0.0681,  0.0906, -0.2800,  0.0826,\n",
              "          0.0927,  0.1752],\n",
              "        [-0.1808, -0.0493,  0.0734, -0.0933, -0.0688,  0.0772, -0.2480,  0.1301,\n",
              "         -0.0401,  0.1569]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sequential block\n",
        "class MySequential(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__()\n",
        "        for idx, module in enumerate(args):\n",
        "            self._modules[str(idx)] = module\n",
        "    \n",
        "    def forward(self, x):\n",
        "        for block in self._modules.values():\n",
        "            x = block(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PwOOUjj632Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "net(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXCLItiz4LWm",
        "outputId": "95ec6f82-c94c-4f00-b904-a028d414e5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0944, -0.0115, -0.1819,  0.0483, -0.1098, -0.1879,  0.0701, -0.1118,\n",
              "         -0.1154,  0.0882],\n",
              "        [ 0.1912, -0.0077, -0.1513,  0.0765, -0.1079, -0.0765,  0.0244, -0.0470,\n",
              "         -0.0554,  0.1280]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fixed parameters\n",
        "class FixedHiddenMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rand_weight = torch.rand((20, 20), requires_grad = False)\n",
        "        self.linear = nn.Linear(20, 20)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = F.relu(torch.mm(x, self.rand_weight) + 1)\n",
        "        x = self.linear(x)\n",
        "        while x.abs().sum() > 1:\n",
        "            x /= 2\n",
        "        return x.sum()"
      ],
      "metadata": {
        "id": "tUn_J6pq4ROw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = FixedHiddenMLP()\n",
        "net(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXZgurmH5Gv2",
        "outputId": "a5191f91-4307-4929-ce7a-6d1f19494270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0386, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random combination\n",
        "class NextMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
        "                                 nn.Linear(64, 32), nn.ReLU())\n",
        "        self.linear = nn.Linear(32, 16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(self.net(x))"
      ],
      "metadata": {
        "id": "FfRYqhA_5WpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chimera = nn.Sequential(NextMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
        "chimera(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR3u0fgj5qJj",
        "outputId": "bbf72724-e3ab-49ec-d384-5cb06201bf24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1032, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter Access"
      ],
      "metadata": {
        "id": "wHQxAHzW56Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
        "x = torch.rand(size = (2, 4))\n",
        "net(x)\n",
        "print(net[2].state_dict())\n",
        "print(net[2].bias)\n",
        "print(net[2].bias.data)\n",
        "print(net[2].weight.grad == None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d18HjRtS5z17",
        "outputId": "e393903c-6230-4955-98d3-98cb37ead327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[ 0.0864, -0.1499, -0.1190,  0.2750, -0.3237, -0.1336, -0.2402, -0.1991]])), ('bias', tensor([-0.1139]))])\n",
            "Parameter containing:\n",
            "tensor([-0.1139], requires_grad=True)\n",
            "tensor([-0.1139])\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all parameters at once\n",
        "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
        "print(*[(name, param.shape) for name, param in net.named_parameters()])\n",
        "# from state_dict()\n",
        "print(net.state_dict()['2.bias'].data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x5CJZ6A6DDa",
        "outputId": "62496b0c-0ecc-4a4c-802f-2c17a761e24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
            "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collecting parameters from nested blocks\n",
        "def block1():\n",
        "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                         nn.Linear(8, 4), nn.ReLU())\n",
        "\n",
        "def block2():\n",
        "    net = nn.Sequential()\n",
        "    for i in range(4):\n",
        "        net.add_module(f'block {i}', block1())\n",
        "    return net\n",
        "\n",
        "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
        "rgnet(x)\n",
        "print(rgnet[0][1][0].bias.data) # nested structure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WVHMVys69-Q",
        "outputId": "fc1e7e36-39ab-447d-fdfd-94dfd265246b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2217],\n",
              "        [-0.2215]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkzO9ETG8fmO",
        "outputId": "28f7f019-36b0-44b7-c83d-93c4abde7fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1958,  0.3506,  0.3878, -0.0791,  0.3250, -0.3055,  0.1278, -0.2377])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rgnet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce332ZoH8KRi",
        "outputId": "cd451056-d74c-48ea-d629-d74d0b53815a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (block 0): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 1): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 2): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 3): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}